{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pylab as plab\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "trainData = data_dir+\"/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution of different sounds in train data\n",
      "jackhammer          0.122907\n",
      "engine_idling       0.114811\n",
      "siren               0.111684\n",
      "air_conditioner     0.110396\n",
      "children_playing    0.110396\n",
      "street_music        0.110396\n",
      "drilling            0.110396\n",
      "dog_bark            0.110396\n",
      "car_horn            0.056302\n",
      "gun_shot            0.042318\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(trainData+\"/train.csv\")\n",
    "print(\"The distribution of different sounds in train data\")\n",
    "dist_train = train.Class.value_counts()/train.Class.count()\n",
    "print(dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor_train(row):\n",
    "    fileName = os.path.join(os.path.abspath(trainData),\"Train\",str(row.ID)+'.wav')\n",
    "    try:\n",
    "        data, sample_rate = librosa.load(fileName, res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y = data, sr = sample_rate, n_mfcc = 40).T, axis = 0)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print (\"Error encountered in \", fileName)\n",
    "        return None, None\n",
    "    feature = mfccs\n",
    "    label = row.Class\n",
    "    #print(\"Feature genereated for \", fileName)\n",
    "    os.system('clear')\n",
    "    return [feature, label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.apply(feature_extractor_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for data in temp:\n",
    "    features.append(list(data[0]))\n",
    "    labels.append(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the data compitable for deeplearning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep neural network to train the data\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainValid, X_test, y_trainValid,y_test = train_test_split(features,y, test_size = 0.2, random_state = 42)\n",
    "X_train, X_valid, y_train,y_valid = train_test_split(X_trainValid,y_trainValid, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4348, 40), (4348, 10), (3478, 40), (3478, 10), (870, 40), (870, 10))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainValid.shape,y_trainValid.shape,X_train.shape,y_train.shape,X_valid.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_no = y.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(label_no))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss ='categorical_crossentropy',metrics=['accuracy'], optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3478 samples, validate on 870 samples\n",
      "Epoch 1/100\n",
      "3478/3478 [==============================] - 1s 326us/step - loss: 12.8227 - acc: 0.1518 - val_loss: 11.9222 - val_acc: 0.2103\n",
      "Epoch 2/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 10.2554 - acc: 0.2191 - val_loss: 3.1420 - val_acc: 0.3678\n",
      "Epoch 3/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 3.4679 - acc: 0.2283 - val_loss: 2.0940 - val_acc: 0.2828\n",
      "Epoch 4/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 2.1186 - acc: 0.2625 - val_loss: 1.9332 - val_acc: 0.3793\n",
      "Epoch 5/100\n",
      "3478/3478 [==============================] - 0s 125us/step - loss: 1.9874 - acc: 0.2984 - val_loss: 1.7528 - val_acc: 0.4448\n",
      "Epoch 6/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 1.8801 - acc: 0.3516 - val_loss: 1.6787 - val_acc: 0.4632\n",
      "Epoch 7/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 1.7714 - acc: 0.3787 - val_loss: 1.5171 - val_acc: 0.4989\n",
      "Epoch 8/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 1.6787 - acc: 0.4114 - val_loss: 1.3786 - val_acc: 0.5632\n",
      "Epoch 9/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 1.5708 - acc: 0.4505 - val_loss: 1.3274 - val_acc: 0.5713\n",
      "Epoch 10/100\n",
      "3478/3478 [==============================] - 0s 121us/step - loss: 1.4743 - acc: 0.4991 - val_loss: 1.2474 - val_acc: 0.5713\n",
      "Epoch 11/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 1.4193 - acc: 0.5026 - val_loss: 1.1857 - val_acc: 0.5943\n",
      "Epoch 12/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 1.3585 - acc: 0.5374 - val_loss: 1.1106 - val_acc: 0.6184\n",
      "Epoch 13/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 1.3054 - acc: 0.5483 - val_loss: 1.1055 - val_acc: 0.6713\n",
      "Epoch 14/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 1.2518 - acc: 0.5750 - val_loss: 1.0487 - val_acc: 0.6954\n",
      "Epoch 15/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 1.2101 - acc: 0.5891 - val_loss: 1.0007 - val_acc: 0.6989\n",
      "Epoch 16/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 1.1704 - acc: 0.5949 - val_loss: 0.9705 - val_acc: 0.7103\n",
      "Epoch 17/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 1.1314 - acc: 0.6116 - val_loss: 0.9352 - val_acc: 0.7333\n",
      "Epoch 18/100\n",
      "3478/3478 [==============================] - 0s 113us/step - loss: 1.0826 - acc: 0.6176 - val_loss: 0.8704 - val_acc: 0.7080\n",
      "Epoch 19/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 1.0269 - acc: 0.6486 - val_loss: 0.8416 - val_acc: 0.7138\n",
      "Epoch 20/100\n",
      "3478/3478 [==============================] - 0s 114us/step - loss: 1.0043 - acc: 0.6535 - val_loss: 0.8241 - val_acc: 0.7207\n",
      "Epoch 21/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 1.0144 - acc: 0.6599 - val_loss: 0.8307 - val_acc: 0.7437\n",
      "Epoch 22/100\n",
      "3478/3478 [==============================] - 0s 125us/step - loss: 0.9557 - acc: 0.6803 - val_loss: 0.7917 - val_acc: 0.7586\n",
      "Epoch 23/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.9369 - acc: 0.6786 - val_loss: 0.7575 - val_acc: 0.7632\n",
      "Epoch 24/100\n",
      "3478/3478 [==============================] - 0s 122us/step - loss: 0.9237 - acc: 0.6947 - val_loss: 0.7631 - val_acc: 0.7736\n",
      "Epoch 25/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.8676 - acc: 0.7059 - val_loss: 0.7403 - val_acc: 0.7563\n",
      "Epoch 26/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.8687 - acc: 0.7090 - val_loss: 0.7009 - val_acc: 0.7713\n",
      "Epoch 27/100\n",
      "3478/3478 [==============================] - 0s 114us/step - loss: 0.8538 - acc: 0.7119 - val_loss: 0.7211 - val_acc: 0.7644\n",
      "Epoch 28/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.8202 - acc: 0.7197 - val_loss: 0.7086 - val_acc: 0.7632\n",
      "Epoch 29/100\n",
      "3478/3478 [==============================] - 0s 114us/step - loss: 0.8123 - acc: 0.7168 - val_loss: 0.6846 - val_acc: 0.7736\n",
      "Epoch 30/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.7880 - acc: 0.7280 - val_loss: 0.6691 - val_acc: 0.7736\n",
      "Epoch 31/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 0.7678 - acc: 0.7401 - val_loss: 0.6567 - val_acc: 0.7839\n",
      "Epoch 32/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.7628 - acc: 0.7392 - val_loss: 0.6506 - val_acc: 0.7816\n",
      "Epoch 33/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.7237 - acc: 0.7510 - val_loss: 0.6432 - val_acc: 0.7816\n",
      "Epoch 34/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.7261 - acc: 0.7573 - val_loss: 0.6468 - val_acc: 0.7805\n",
      "Epoch 35/100\n",
      "3478/3478 [==============================] - 0s 114us/step - loss: 0.7208 - acc: 0.7545 - val_loss: 0.5983 - val_acc: 0.7920\n",
      "Epoch 36/100\n",
      "3478/3478 [==============================] - 0s 123us/step - loss: 0.7135 - acc: 0.7596 - val_loss: 0.6162 - val_acc: 0.7874\n",
      "Epoch 37/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.7009 - acc: 0.7665 - val_loss: 0.6261 - val_acc: 0.7862\n",
      "Epoch 38/100\n",
      "3478/3478 [==============================] - 0s 123us/step - loss: 0.6949 - acc: 0.7685 - val_loss: 0.5890 - val_acc: 0.8092\n",
      "Epoch 39/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.6827 - acc: 0.7611 - val_loss: 0.6116 - val_acc: 0.7920\n",
      "Epoch 40/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.6920 - acc: 0.7651 - val_loss: 0.5900 - val_acc: 0.8080\n",
      "Epoch 41/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.6414 - acc: 0.7884 - val_loss: 0.5827 - val_acc: 0.8011\n",
      "Epoch 42/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 0.6507 - acc: 0.7772 - val_loss: 0.5749 - val_acc: 0.8126\n",
      "Epoch 43/100\n",
      "3478/3478 [==============================] - 0s 123us/step - loss: 0.6319 - acc: 0.7887 - val_loss: 0.5707 - val_acc: 0.8126\n",
      "Epoch 44/100\n",
      "3478/3478 [==============================] - 0s 121us/step - loss: 0.6245 - acc: 0.7872 - val_loss: 0.5723 - val_acc: 0.8126\n",
      "Epoch 45/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.6332 - acc: 0.7823 - val_loss: 0.5477 - val_acc: 0.8230\n",
      "Epoch 46/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.6113 - acc: 0.7872 - val_loss: 0.5804 - val_acc: 0.8115\n",
      "Epoch 47/100\n",
      "3478/3478 [==============================] - 0s 111us/step - loss: 0.5952 - acc: 0.7964 - val_loss: 0.5236 - val_acc: 0.8310\n",
      "Epoch 48/100\n",
      "3478/3478 [==============================] - 0s 110us/step - loss: 0.5870 - acc: 0.7964 - val_loss: 0.5216 - val_acc: 0.8276\n",
      "Epoch 49/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.5717 - acc: 0.8076 - val_loss: 0.5301 - val_acc: 0.8345\n",
      "Epoch 50/100\n",
      "3478/3478 [==============================] - 0s 121us/step - loss: 0.5451 - acc: 0.8099 - val_loss: 0.5268 - val_acc: 0.8299\n",
      "Epoch 51/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.5775 - acc: 0.8134 - val_loss: 0.5164 - val_acc: 0.8276\n",
      "Epoch 52/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.5391 - acc: 0.8174 - val_loss: 0.5115 - val_acc: 0.8345\n",
      "Epoch 53/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 0.5397 - acc: 0.8220 - val_loss: 0.5176 - val_acc: 0.8356\n",
      "Epoch 54/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.5196 - acc: 0.8272 - val_loss: 0.4736 - val_acc: 0.8379\n",
      "Epoch 55/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.5217 - acc: 0.8200 - val_loss: 0.4724 - val_acc: 0.8494\n",
      "Epoch 56/100\n",
      "3478/3478 [==============================] - 0s 124us/step - loss: 0.5490 - acc: 0.8298 - val_loss: 0.4740 - val_acc: 0.8448\n",
      "Epoch 57/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 0.4969 - acc: 0.8281 - val_loss: 0.4877 - val_acc: 0.8471\n",
      "Epoch 58/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 0.5434 - acc: 0.8137 - val_loss: 0.5165 - val_acc: 0.8276\n",
      "Epoch 59/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4780 - acc: 0.8344 - val_loss: 0.4822 - val_acc: 0.8586\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4855 - acc: 0.8283 - val_loss: 0.4795 - val_acc: 0.8506\n",
      "Epoch 61/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.5134 - acc: 0.8341 - val_loss: 0.4745 - val_acc: 0.8517\n",
      "Epoch 62/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.5110 - acc: 0.8321 - val_loss: 0.5106 - val_acc: 0.8299\n",
      "Epoch 63/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4973 - acc: 0.8347 - val_loss: 0.4770 - val_acc: 0.8494\n",
      "Epoch 64/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4959 - acc: 0.8292 - val_loss: 0.4957 - val_acc: 0.8448\n",
      "Epoch 65/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.4976 - acc: 0.8306 - val_loss: 0.4518 - val_acc: 0.8460\n",
      "Epoch 66/100\n",
      "3478/3478 [==============================] - 0s 113us/step - loss: 0.4787 - acc: 0.8381 - val_loss: 0.4549 - val_acc: 0.8621\n",
      "Epoch 67/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4817 - acc: 0.8258 - val_loss: 0.4565 - val_acc: 0.8529\n",
      "Epoch 68/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4637 - acc: 0.8439 - val_loss: 0.4404 - val_acc: 0.8632\n",
      "Epoch 69/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4564 - acc: 0.8482 - val_loss: 0.4527 - val_acc: 0.8575\n",
      "Epoch 70/100\n",
      "3478/3478 [==============================] - 0s 123us/step - loss: 0.4872 - acc: 0.8419 - val_loss: 0.4627 - val_acc: 0.8460\n",
      "Epoch 71/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4372 - acc: 0.8511 - val_loss: 0.4690 - val_acc: 0.8356\n",
      "Epoch 72/100\n",
      "3478/3478 [==============================] - 0s 114us/step - loss: 0.4667 - acc: 0.8442 - val_loss: 0.4468 - val_acc: 0.8540\n",
      "Epoch 73/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4677 - acc: 0.8459 - val_loss: 0.4238 - val_acc: 0.8655\n",
      "Epoch 74/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4222 - acc: 0.8580 - val_loss: 0.4650 - val_acc: 0.8494\n",
      "Epoch 75/100\n",
      "3478/3478 [==============================] - 0s 115us/step - loss: 0.4413 - acc: 0.8568 - val_loss: 0.4411 - val_acc: 0.8598\n",
      "Epoch 76/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 0.4612 - acc: 0.8554 - val_loss: 0.4226 - val_acc: 0.8690\n",
      "Epoch 77/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4336 - acc: 0.8585 - val_loss: 0.4170 - val_acc: 0.8667\n",
      "Epoch 78/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.4136 - acc: 0.8623 - val_loss: 0.4202 - val_acc: 0.8632\n",
      "Epoch 79/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.4213 - acc: 0.8652 - val_loss: 0.4554 - val_acc: 0.8586\n",
      "Epoch 80/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.4145 - acc: 0.8588 - val_loss: 0.4364 - val_acc: 0.8563\n",
      "Epoch 81/100\n",
      "3478/3478 [==============================] - 0s 113us/step - loss: 0.4315 - acc: 0.8611 - val_loss: 0.4415 - val_acc: 0.8701\n",
      "Epoch 82/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.4446 - acc: 0.8542 - val_loss: 0.4296 - val_acc: 0.8713\n",
      "Epoch 83/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4007 - acc: 0.8594 - val_loss: 0.4338 - val_acc: 0.8667\n",
      "Epoch 84/100\n",
      "3478/3478 [==============================] - 0s 116us/step - loss: 0.4140 - acc: 0.8652 - val_loss: 0.3966 - val_acc: 0.8839\n",
      "Epoch 85/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.4112 - acc: 0.8634 - val_loss: 0.4266 - val_acc: 0.8724\n",
      "Epoch 86/100\n",
      "3478/3478 [==============================] - 0s 121us/step - loss: 0.4036 - acc: 0.8640 - val_loss: 0.4204 - val_acc: 0.8644\n",
      "Epoch 87/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.3971 - acc: 0.8689 - val_loss: 0.4231 - val_acc: 0.8747\n",
      "Epoch 88/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.4053 - acc: 0.8700 - val_loss: 0.4075 - val_acc: 0.8713\n",
      "Epoch 89/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.4136 - acc: 0.8643 - val_loss: 0.4063 - val_acc: 0.8759\n",
      "Epoch 90/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.3634 - acc: 0.8790 - val_loss: 0.4631 - val_acc: 0.8655\n",
      "Epoch 91/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.4009 - acc: 0.8666 - val_loss: 0.4278 - val_acc: 0.8759\n",
      "Epoch 92/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 0.3776 - acc: 0.8755 - val_loss: 0.4446 - val_acc: 0.8678\n",
      "Epoch 93/100\n",
      "3478/3478 [==============================] - 0s 113us/step - loss: 0.3839 - acc: 0.8723 - val_loss: 0.3952 - val_acc: 0.8736\n",
      "Epoch 94/100\n",
      "3478/3478 [==============================] - 0s 131us/step - loss: 0.3598 - acc: 0.8790 - val_loss: 0.4345 - val_acc: 0.8701\n",
      "Epoch 95/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 0.3736 - acc: 0.8732 - val_loss: 0.4201 - val_acc: 0.8701\n",
      "Epoch 96/100\n",
      "3478/3478 [==============================] - 0s 120us/step - loss: 0.3637 - acc: 0.8775 - val_loss: 0.4282 - val_acc: 0.8690\n",
      "Epoch 97/100\n",
      "3478/3478 [==============================] - 0s 117us/step - loss: 0.3781 - acc: 0.8764 - val_loss: 0.4147 - val_acc: 0.8644\n",
      "Epoch 98/100\n",
      "3478/3478 [==============================] - 0s 118us/step - loss: 0.3796 - acc: 0.8729 - val_loss: 0.4160 - val_acc: 0.8770\n",
      "Epoch 99/100\n",
      "3478/3478 [==============================] - 0s 121us/step - loss: 0.3883 - acc: 0.8703 - val_loss: 0.4287 - val_acc: 0.8644\n",
      "Epoch 100/100\n",
      "3478/3478 [==============================] - 0s 119us/step - loss: 0.4226 - acc: 0.8640 - val_loss: 0.4290 - val_acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc440290550>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.889604\n",
      "The confusion matrix is:\n",
      "[[126   0   2   2   0   0   0   0   0   1]\n",
      " [  0  39   1   0   0   0   0   0   0   0]\n",
      " [  4   0  88   9   4   0   6   0   2  18]\n",
      " [  0   1   3  91   3   0   1   0   5   3]\n",
      " [  0   2   1   4 124   0   0   1   0   1]\n",
      " [  0   1   1   2   0 126   0   0   0   2]\n",
      " [  0   0   0   0   0   0  33   0   0   0]\n",
      " [  0   0   2   0   0   0   0 141   0   1]\n",
      " [  0   0   0   5   0   2   0   0 104   1]\n",
      " [  3   5   9   4   2   2   0   3   1  95]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Validation Phase\n",
    "labels_test_Predicted = model.predict(X_test)\n",
    "labels_test_Predicted = [np.argmax(test_y, axis=None, out=None) for test_y in labels_test_Predicted]\n",
    "y_test_index = [np.argmax(test_y, axis=None, out=None) for test_y in y_test]\n",
    "cm=metrics.confusion_matrix(labels_test_Predicted,y_test_index)\n",
    "accuracy = metrics.accuracy_score(y_test_index,labels_test_Predicted)\n",
    "print(\"The accuracy is %f\"%accuracy)\n",
    "print(\"The confusion matrix is:\")\n",
    "print(cm)\n",
    "plab.matshow(cm)\n",
    "plab.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
