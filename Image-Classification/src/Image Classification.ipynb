{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import sklearn as sl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('../samples')\n",
    "\n",
    "imagesTrain, labelsTrain = mndata.load_training()\n",
    "imagesTest, labelsTest = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      ".....................@@.....\n",
      ".............@@@@@@.@@......\n",
      "........@@@@@@@@@@..........\n",
      "........@@@@@@..@@..........\n",
      "...........@@@..............\n",
      "............@...............\n",
      "............@...............\n",
      ".............@..............\n",
      ".............@@.............\n",
      "..............@@@...........\n",
      "................@@..........\n",
      ".................@@.........\n",
      ".................@@@........\n",
      ".................@@@........\n",
      "..............@@@@@.........\n",
      "............@@@@@@..........\n",
      "..........@@@@@.............\n",
      "........@@@@@...............\n",
      "......@@@@@@................\n",
      ".....@@@@...................\n",
      "............................\n",
      "............................\n",
      "............................ 5\n"
     ]
    }
   ],
   "source": [
    "print(mndata.display(imagesTrain[0]),labelsTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all the minst representation into 1 and 0\n",
    "def imageToBinary(imageList):\n",
    "    imageBinary = []\n",
    "    for image in imageList:\n",
    "        image = np.array(image)>0\n",
    "        image = image * 1\n",
    "        image = list(image)\n",
    "        imageBinary.append(image)\n",
    "        \n",
    "    return imageBinary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTrainBinary = imageToBinary(imagesTrain)\n",
    "imagesTestBinary = imageToBinary(imagesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTrainDf = pd.DataFrame(imagesTrainBinary)\n",
    "trainLabelDf = pd.DataFrame(list(labelsTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabelDf.columns = [\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabelDf.label = trainLabelDf.label.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.concat([imageTrainDf,trainLabelDf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...    775  776  777  778  779  780  781  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "\n",
       "   782  783  label  \n",
       "0    0    0      5  \n",
       "1    0    0      0  \n",
       "2    0    0      4  \n",
       "3    0    0      1  \n",
       "4    0    0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of 5 : 0.090350\n",
      "fraction of 0 : 0.098717\n",
      "fraction of 4 : 0.097367\n",
      "fraction of 1 : 0.112367\n",
      "fraction of 9 : 0.099150\n",
      "fraction of 2 : 0.099300\n",
      "fraction of 3 : 0.102183\n",
      "fraction of 6 : 0.098633\n",
      "fraction of 7 : 0.104417\n",
      "fraction of 8 : 0.097517\n"
     ]
    }
   ],
   "source": [
    "unique_class =trainDf['label'].unique()\n",
    "for class_tag in unique_class:\n",
    "    count = sum(trainDf['label'] == class_tag)\n",
    "    print(\"fraction of %s : %f\"%(class_tag, count/len(trainDf['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = trainDf[trainDf.columns[:-1]].values\n",
    "y = trainDf[trainDf.columns[-1]].values\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state =  42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "logistic = linear_model.LogisticRegression(solver = 'sag', max_iter = 1000, \\\n",
    "                                           multi_class = 'multinomial',C = 1e5, warm_start = True, penalty='l2',tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=1000,\n",
       "          multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "          random_state=None, solver='sag', tol=0.01, verbose=0,\n",
       "          warm_start=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score in train set: 0.936771\n",
      "The score in the valid set: 0.911250\n"
     ]
    }
   ],
   "source": [
    "print(\"The score in train set: %f\"%logistic.score(X_train,y_train))\n",
    "print(\"The score in the valid set: %f\"%(logistic.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1120    0    6    4    7   11    9    1   15    2]\n",
      " [   0 1279   11    6    2    6    4    0   13    1]\n",
      " [   3   14 1056   17   12    5   15   14   28   10]\n",
      " [   6    8   36 1071    1   36    2   12   29   18]\n",
      " [   3    4   10    4 1081    4   11    5   12   42]\n",
      " [  24    6   11   44   12  950   13    6   32    6]\n",
      " [   9    2   21    4   10   19 1106    0    6    0]\n",
      " [   2    4   14   13   10    1    0 1204    7   44]\n",
      " [  10   22   24   30    8   36   12    2 1003   13]\n",
      " [   6    6    6   15   38    5    0   44    9 1065]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted_valid = logistic.predict(X_valid)\n",
    "print(confusion_matrix(y_valid,y_predicted_valid))\n",
    "#plt.matshow(confusion_matrix(y_valid,y_predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us test the test set\n",
    "X_test = np.asarray(imagesTestBinary)\n",
    "y_test_array = np.array(labelsTest)\n",
    "y_test = y_test_array.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score in test set: 0.914300\n"
     ]
    }
   ],
   "source": [
    "predicted_test = logistic.predict(X_test)\n",
    "print(\"The score in test set: %f\"%logistic.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us try using KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors = 10, weights = 'uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score in train set: 0.969479\n",
      "The score in the valid set: 0.964000\n"
     ]
    }
   ],
   "source": [
    "print(\"The score in train set: %f\"%neigh.score(X_train,y_train))\n",
    "print(\"The score in the valid set: %f\"%(neigh.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score in train set: 0.960600\n"
     ]
    }
   ],
   "source": [
    "print(\"The score in train set: %f\"%neigh.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM for classification\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(gamma = 'scale', C = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_valid = svm_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score in test set: 0.973800\n",
      "The score in the train set: 0.973250\n"
     ]
    }
   ],
   "source": [
    "print(\"The score in test set: %f\"%svm_clf.score(X_test,y_test))\n",
    "print(\"The score in the train set: %f\"%(svm_clf.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN training \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "sc = StandardScaler()\n",
    "lb = LabelEncoder()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_valid = sc.transform(X_valid)\n",
    "\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)\n",
    "y_valid = lb.fit_transform(y_valid)\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_valid = np_utils.to_categorical(y_valid)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 31s 642us/step - loss: 0.4882 - acc: 0.8575 - val_loss: 0.2225 - val_acc: 0.9402\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 18s 383us/step - loss: 0.2553 - acc: 0.9344 - val_loss: 0.1719 - val_acc: 0.9557\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 19s 403us/step - loss: 0.2021 - acc: 0.9486 - val_loss: 0.1744 - val_acc: 0.9564\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 19s 386us/step - loss: 0.1774 - acc: 0.9542 - val_loss: 0.1687 - val_acc: 0.9608\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 18s 384us/step - loss: 0.1584 - acc: 0.9599 - val_loss: 0.1739 - val_acc: 0.9620\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 19s 388us/step - loss: 0.1485 - acc: 0.9634 - val_loss: 0.1633 - val_acc: 0.9651\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 19s 393us/step - loss: 0.1333 - acc: 0.9665 - val_loss: 0.1761 - val_acc: 0.9660\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 19s 396us/step - loss: 0.1268 - acc: 0.9694 - val_loss: 0.1872 - val_acc: 0.9626\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 19s 395us/step - loss: 0.1192 - acc: 0.9716 - val_loss: 0.1877 - val_acc: 0.9639\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 19s 404us/step - loss: 0.1152 - acc: 0.9726 - val_loss: 0.1881 - val_acc: 0.9674\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 19s 392us/step - loss: 0.1010 - acc: 0.9753 - val_loss: 0.2016 - val_acc: 0.9656\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 19s 387us/step - loss: 0.1058 - acc: 0.9751 - val_loss: 0.2077 - val_acc: 0.9647\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 20s 425us/step - loss: 0.1024 - acc: 0.9761 - val_loss: 0.1967 - val_acc: 0.9645\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 23s 475us/step - loss: 0.0923 - acc: 0.9787 - val_loss: 0.2050 - val_acc: 0.9674\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 25s 518us/step - loss: 0.1011 - acc: 0.9776 - val_loss: 0.1957 - val_acc: 0.9674\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 22s 454us/step - loss: 0.0963 - acc: 0.9786 - val_loss: 0.2211 - val_acc: 0.9684\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 19s 391us/step - loss: 0.0850 - acc: 0.9800 - val_loss: 0.2001 - val_acc: 0.9667\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 19s 402us/step - loss: 0.0873 - acc: 0.9800 - val_loss: 0.2009 - val_acc: 0.9701\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 19s 399us/step - loss: 0.0959 - acc: 0.9799 - val_loss: 0.1664 - val_acc: 0.9687\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 20s 407us/step - loss: 0.0874 - acc: 0.9807 - val_loss: 0.1955 - val_acc: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa8ff72c88>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu', input_dim = 784))\n",
    "\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 20,validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model\n",
    "y_test_prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = [np.argmax(test_y, axis=None, out=None) for test_y in y_test_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_label = lb.inverse_transform(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = y_prediction_label.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the test data is  0.9675\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the test data is \",metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use of CNN to train MNIST data\n",
    "image=np.array(imagesTrain[0])\n",
    "mn = image.size\n",
    "m = int(np.sqrt(mn))\n",
    "imageReshaped = np.reshape(image,(m,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xa90461240>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAADoBJREFUeJzt3X2MXOV1x/HfyXq9jo1JvHHYboiLHeMEiGlMOjIgLKCiuA5CMiiKiRVFDiFxmuCktK4EdavGrWjlVgmRQynS0ri2I95CAsJ/0CR0FUGiwpbFMeYtvJlNY7PsYjZgQ4i9Xp/+sdfRBnaeWc/cmTu75/uRVjtzz71zj6792zszz8x9zN0FIJ53Fd0AgGIQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQU1r5M6mW5vP0KxG7hII5bd6U4f9kE1k3ZrCb2YrJG2W1CLpP9x9U2r9GZqls+2iWnYJIKHHuye8btVP+82sRdJNkj4h6QxJq83sjGofD0Bj1fKaf6mk5919j7sflnSHpJX5tAWg3moJ/8mSfjXm/t5s2e8xs7Vm1mtmvcM6VMPuAOSp7u/2u3uXu5fcvdSqtnrvDsAE1RL+fZLmjbn/wWwZgEmglvA/ImmRmS0ws+mSPi1pRz5tAai3qof63P2Ima2T9CONDvVtcfcnc+sMQF3VNM7v7vdJui+nXgA0EB/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiaZuk1sz5JByWNSDri7qU8mkJ+bFr6n7jl/XPruv9n/np+2drIzKPJbU9ZOJisz/yKJesv3zC9bG1n6c7ktvtH3kzWz75rfbJ+6l89nKw3g5rCn/kTd9+fw+MAaCCe9gNB1Rp+l/RjM3vUzNbm0RCAxqj1af8yd99nZidJut/MfuHuD45dIfujsFaSZmhmjbsDkJeazvzuvi/7PSjpHklLx1mny91L7l5qVVstuwOQo6rDb2azzGz2sduSlkt6Iq/GANRXLU/7OyTdY2bHHuc2d/9hLl0BqLuqw+/ueyR9LMdepqyW0xcl697Wmqy/dMF7k/W3zik/Jt3+nvR49U8/lh7vLtJ//WZ2sv4v/7YiWe8587aytReH30puu2ng4mT9Az/1ZH0yYKgPCIrwA0ERfiAowg8ERfiBoAg/EFQe3+oLb+TCjyfrN2y9KVn/cGv5r55OZcM+kqz//Y2fS9anvZkebjv3rnVla7P3HUlu27Y/PRQ4s7cnWZ8MOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8+eg7ZmXkvVHfzsvWf9w60Ce7eRqff85yfqeN9KX/t668Ptla68fTY/Td3z7f5L1epr8X9itjDM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRl7o0b0TzR2v1su6hh+2sWQ1eem6wfWJG+vHbL7hOS9ce+cuNx93TM9fv/KFl/5IL0OP7Ia68n635u+au7930tuakWrH4svQLeoce7dcCH0nOXZzjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQFcf5zWyLpEslDbr74mxZu6Q7Jc2X1Cdplbv/utLOoo7zV9Iy933J+sirQ8n6i7eVH6t/8vwtyW2X/vNXk/WTbiruO/U4fnmP82+V9PaJ0K+T1O3uiyR1Z/cBTCIVw+/uD0p6+6lnpaRt2e1tki7LuS8AdVbta/4Od+/Pbr8sqSOnfgA0SM1v+PnomwZl3zgws7Vm1mtmvcM6VOvuAOSk2vAPmFmnJGW/B8ut6O5d7l5y91Kr2qrcHYC8VRv+HZLWZLfXSLo3n3YANErF8JvZ7ZIekvQRM9trZldJ2iTpYjN7TtKfZvcBTCIVr9vv7qvLlBiwz8nI/ldr2n74wPSqt/3oZ55K1l+5uSX9AEdHqt43isUn/ICgCD8QFOEHgiL8QFCEHwiK8ANBMUX3FHD6tc+WrV15ZnpE9j9P6U7WL/jU1cn67DsfTtbRvDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPNPAalpsl/98unJbf9vx1vJ+nXXb0/W/2bV5cm6//w9ZWvz/umh5LZq4PTxEXHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKk7RnSem6G4+Q58/N1m/9evfSNYXTJtR9b4/un1dsr7olv5k/cievqr3PVXlPUU3gCmI8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2ZbJF0qadDdF2fLNkr6oqRXstU2uPt9lXbGOP/k4+ctSdZP3LQ3Wb/9Qz+qet+n/eQLyfpH/qH8dQwkaeS5PVXve7LKe5x/q6QV4yz/lrsvyX4qBh9Ac6kYfnd/UNJQA3oB0EC1vOZfZ2a7zWyLmc3JrSMADVFt+G+WtFDSEkn9kr5ZbkUzW2tmvWbWO6xDVe4OQN6qCr+7D7j7iLsflXSLpKWJdbvcveTupVa1VdsngJxVFX4z6xxz93JJT+TTDoBGqXjpbjO7XdKFkuaa2V5JX5d0oZktkeSS+iR9qY49AqgDvs+PmrR0nJSsv3TFqWVrPdduTm77rgpPTD/z4vJk/fVlrybrUxHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3Tpifrv/HDyfqlX72m/GPf05PcdrJiqA9ARYQfCIrwA0ERfiAowg8ERfiBoAg/EFTF7/MjtqPL0pfufuFT6Sm6Fy/pK1urNI5fyY1DZyXrM+/trenxpzrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8U5yVFifrz34tPdZ+y3nbkvXzZ6S/U1+LQz6crD88tCD9AEf7c+xm6uHMDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBVRznN7N5krZL6pDkkrrcfbOZtUu6U9J8SX2SVrn7r+vXalzTFpySrL9w5QfK1jZecUdy20+esL+qnvKwYaCUrD+w+Zxkfc629HX/kTaRM/8RSevd/QxJ50i62szOkHSdpG53XySpO7sPYJKoGH5373f3ndntg5KelnSypJWSjn38a5uky+rVJID8HddrfjObL+ksST2SOtz92OcnX9boywIAk8SEw29mJ0j6gaRr3P3A2JqPTvg37qR/ZrbWzHrNrHdYh2pqFkB+JhR+M2vVaPBvdfe7s8UDZtaZ1TslDY63rbt3uXvJ3UutasujZwA5qBh+MzNJ35H0tLvfMKa0Q9Ka7PYaSffm3x6AepnIV3rPk/RZSY+b2a5s2QZJmyR9z8yukvRLSavq0+LkN23+Hybrr/9xZ7J+xT/+MFn/8/fenazX0/r+9HDcQ/9efjivfev/Jredc5ShvHqqGH53/5mkcvN9X5RvOwAahU/4AUERfiAowg8ERfiBoAg/EBThB4Li0t0TNK3zD8rWhrbMSm775QUPJOurZw9U1VMe1u1blqzvvDk9Rffc7z+RrLcfZKy+WXHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgwozzH/6z9GWiD//lULK+4dT7ytaWv/vNqnrKy8DIW2Vr5+9Yn9z2tL/7RbLe/lp6nP5osopmxpkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM87fd1n679yzZ95Vt33f9NrCZH3zA8uTdRspd+X0Uadd/2LZ2qKBnuS2I8kqpjLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl7egWzeZK2S+qQ5JK63H2zmW2U9EVJr2SrbnD38l96l3SitfvZxqzeQL30eLcO+FD6gyGZiXzI54ik9e6+08xmS3rUzO7Pat9y929U2yiA4lQMv7v3S+rPbh80s6clnVzvxgDU13G95jez+ZLOknTsM6PrzGy3mW0xszlltllrZr1m1jusQzU1CyA/Ew6/mZ0g6QeSrnH3A5JulrRQ0hKNPjP45njbuXuXu5fcvdSqthxaBpCHCYXfzFo1Gvxb3f1uSXL3AXcfcfejkm6RtLR+bQLIW8Xwm5lJ+o6kp939hjHLO8esdrmk9HStAJrKRN7tP0/SZyU9bma7smUbJK02syUaHf7rk/SlunQIoC4m8m7/zySNN26YHNMH0Nz4hB8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoipfuznVnZq9I+uWYRXMl7W9YA8enWXtr1r4keqtWnr2d4u7vn8iKDQ3/O3Zu1uvupcIaSGjW3pq1L4neqlVUbzztB4Ii/EBQRYe/q+D9pzRrb83al0Rv1Sqkt0Jf8wMoTtFnfgAFKST8ZrbCzJ4xs+fN7LoieijHzPrM7HEz22VmvQX3ssXMBs3siTHL2s3sfjN7Lvs97jRpBfW20cz2Zcdul5ldUlBv88zsJ2b2lJk9aWZ/kS0v9Ngl+irkuDX8ab+ZtUh6VtLFkvZKekTSand/qqGNlGFmfZJK7l74mLCZnS/pDUnb3X1xtuxfJQ25+6bsD+ccd7+2SXrbKOmNomduziaU6Rw7s7SkyyR9TgUeu0Rfq1TAcSvizL9U0vPuvsfdD0u6Q9LKAvpoeu7+oKShty1eKWlbdnubRv/zNFyZ3pqCu/e7+87s9kFJx2aWLvTYJfoqRBHhP1nSr8bc36vmmvLbJf3YzB41s7VFNzOOjmzadEl6WVJHkc2Mo+LMzY30tpmlm+bYVTPjdd54w++dlrn7xyV9QtLV2dPbpuSjr9maabhmQjM3N8o4M0v/TpHHrtoZr/NWRPj3SZo35v4Hs2VNwd33Zb8HJd2j5pt9eODYJKnZ78GC+/mdZpq5ebyZpdUEx66ZZrwuIvyPSFpkZgvMbLqkT0vaUUAf72Bms7I3YmRmsyQtV/PNPrxD0prs9hpJ9xbYy+9plpmby80srYKPXdPNeO3uDf+RdIlG3/F/QdLfFtFDmb4+JOmx7OfJonuTdLtGnwYOa/S9kaskvU9St6TnJP23pPYm6u27kh6XtFujQessqLdlGn1Kv1vSruznkqKPXaKvQo4bn/ADguINPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imageReshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTrainReshaped = []\n",
    "for images in imagesTrain:\n",
    "    train = np.reshape(images,(m,m)).astype(\"float32\")/255.0\n",
    "    imagesTrainReshaped.append(train[:,:,np.newaxis])\n",
    "    \n",
    "imagesTrainReshaped = np.array(imagesTrainReshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesTestReshaped = []\n",
    "for images in imagesTest:\n",
    "    test = np.reshape(images,(m,m)).astype(\"float32\")/255.0\n",
    "    imagesTestReshaped.append(test[:,:,np.newaxis])\n",
    "imagesTestReshaped = np.array(imagesTestReshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(imagesTrainReshaped, labelsTrain, test_size = 0.2, random_state =  42 )\n",
    "X_test = imagesTestReshaped\n",
    "y_test = labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)\n",
    "y_valid = lb.fit_transform(y_valid)\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_valid = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 418s 9ms/step - loss: 0.2916 - acc: 0.9102 - val_loss: 0.0774 - val_acc: 0.9767\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 141s 3ms/step - loss: 0.1014 - acc: 0.9711 - val_loss: 0.0548 - val_acc: 0.9827\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 140s 3ms/step - loss: 0.0724 - acc: 0.9782 - val_loss: 0.0539 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 142s 3ms/step - loss: 0.0593 - acc: 0.9819 - val_loss: 0.0442 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.0464 - acc: 0.9861 - val_loss: 0.0524 - val_acc: 0.9863\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.0390 - acc: 0.9876 - val_loss: 0.0411 - val_acc: 0.9891\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.0326 - acc: 0.9893 - val_loss: 0.0439 - val_acc: 0.9887\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.0297 - acc: 0.9911 - val_loss: 0.0416 - val_acc: 0.9892\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.0265 - acc: 0.9914 - val_loss: 0.0436 - val_acc: 0.9898\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.0244 - acc: 0.9924 - val_loss: 0.0419 - val_acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa281c1780>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3), activation = 'relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs = 10, verbose = 1, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(imagesTestReshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = [np.argmax(test_y, axis=None, out=None) for test_y in y_predict]\n",
    "y_test_label = [np.argmax(test_y, axis=None, out=None) for test_y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = lb.inverse_transform(y_prediction)\n",
    "y_test = lb.inverse_transform(y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.991\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is \", metrics.accuracy_score(y_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
