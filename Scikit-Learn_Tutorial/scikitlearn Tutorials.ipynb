{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as num\n",
    "import pylab as lab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg=linear_model.LinearRegression()\n",
    "reg.fit([[0,0],[1,1],[2,2]],[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1102230246251565e-16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regRidge=linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regRidge.alpha=0.5\n",
    "regRidge.fit([[0,0],[1,1],[2,2]],[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44444444, 0.44444444]), 0.11111111111111116)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regRidge.coef_,regRidge.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "For classification, as in the labeling iris task, linear regression is not the right approach as it will give too much weights to the data far from the decision frontier. A linear approach is to fit a sigmod funcion or logistic fucntion\n",
    "\n",
    "$$y=sigmoid(X\\beta-offset)+\\epsilon=\\frac{1}{1+\\exp(-X\\beta + offset)}+\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=linear_model.LogisticRegression(solver='lbfgs',C=1e5,multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "iris_X=iris.data\n",
    "iris_y=iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.random.seed(0)\n",
    "indices=num.random.permutation(len(iris_X))\n",
    "iris_X_train = iris_X[indices[:-10]]\n",
    "iris_y_train = iris_y[indices[:-10]]\n",
    "iris_X_test = iris_X[indices[-10:]]\n",
    "iris_y_test = iris_y[indices[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model.logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(linear_model.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "          random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(iris_X_train,iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0]), array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict(iris_X_test),iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.64095772e-08, 9.99988145e-01, 1.18090442e-05],\n",
       "       [2.08290156e-11, 2.11068316e-01, 7.88931684e-01],\n",
       "       [5.76927941e-12, 9.99810641e-01, 1.89359089e-04],\n",
       "       [1.00000000e+00, 4.77285124e-12, 2.57964494e-36],\n",
       "       [1.00000000e+00, 3.83638508e-11, 6.52284417e-33],\n",
       "       [9.99999944e-01, 5.64219520e-08, 1.27425122e-30],\n",
       "       [1.07851175e-19, 2.93453472e-04, 9.99706547e-01],\n",
       "       [3.96902019e-09, 9.99999870e-01, 1.26070139e-07],\n",
       "       [4.87953747e-23, 8.82869528e-08, 9.99999912e-01],\n",
       "       [9.99999984e-01, 1.59778123e-08, 1.53573775e-30]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(iris_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import time\n",
    "digits=datasets.load_digits()\n",
    "digits_X=digits.data/digits.data.max()\n",
    "digits_y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.random.seed(0)\n",
    "indices=num.random.permutation(len(digits_X))\n",
    "digits_X_train = digits_X[indices[:-10]]\n",
    "digits_y_train = digits_y[indices[:-10]]\n",
    "digits_X_test = digits_X[indices[-10:]]\n",
    "digits_y_test = digits_y[indices[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on KNeighborsClassifier in module sklearn.neighbors.classification object:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors.base.NeighborsBase, sklearn.neighbors.base.KNeighborsMixin, sklearn.neighbors.base.SupervisedIntegerMixin, sklearn.base.ClassifierMixin)\n",
      " |  KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, optional (default = 5)\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : str or callable, optional (default = 'uniform')\n",
      " |      weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, optional (default = 30)\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : integer, optional (default = 2)\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : string or callable, default 'minkowski'\n",
      " |      the distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. See the documentation of the DistanceMetric class for a\n",
      " |      list of available metrics.\n",
      " |  \n",
      " |  metric_params : dict, optional (default = None)\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.66666667 0.33333333]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier\n",
      " |  KNeighborsRegressor\n",
      " |  RadiusNeighborsRegressor\n",
      " |  NearestNeighbors\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors.base.NeighborsBase\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.neighbors.base.KNeighborsMixin\n",
      " |      sklearn.neighbors.base.SupervisedIntegerMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape [n_samples] or [n_samples, n_outputs]\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Finds the K-neighbors of a point.\n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors to get (default is the value\n",
      " |          passed to the constructor).\n",
      " |      \n",
      " |      return_distance : boolean, optional. Defaults to True.\n",
      " |          If False, distances will not be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dist : array\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True\n",
      " |      \n",
      " |      ind : array\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NeighborsClassifier\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Computes the (weighted) graph of k-Neighbors for points in X\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors for each sample.\n",
      " |          (default is value passed to the constructor).\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, optional\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are Euclidean distance between points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse matrix in CSR format, shape = [n_samples, n_samples_fit]\n",
      " |          n_samples_fit is the number of samples in the fitted data\n",
      " |          A[i, j] is assigned the weight of edge that connects i to j.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.SupervisedIntegerMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model using X as training data and y as target values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, BallTree, KDTree}\n",
      " |          Training data. If array or matrix, shape [n_samples, n_features],\n",
      " |          or [n_samples, n_samples] if metric='precomputed'.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix}\n",
      " |          Target values of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1060183048248291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9904868494683827"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=time.time()\n",
    "knn.fit(digits_X_train,digits_y_train)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "knn.score(digits_X_train,digits_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 8, 4, 5, 3, 3, 7, 7, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn.predict(digits_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 8, 4, 5, 3, 3, 7, 7, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying logistic regression for the classification of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=LogisticRegression()\n",
    "log.multi_class='multinomial'\n",
    "log.solver='lbfgs'\n",
    "log.max_iter=500\n",
    "log.C=1e4\n",
    "log.random_state=0\n",
    "log.warm_start=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1144707202911377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=time.time()\n",
    "log.fit(digits_X_train,digits_y_train)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "log.score(digits_X_train,digits_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogisticRegression in module sklearn.linear_model.logistic object:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 8, 4, 5, 3, 3, 7, 7, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict(digits_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 8, 4, 5, 3, 3, 7, 7, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im=digits_X_test[-1].reshape(8,8)\n",
    "lab.imshow(im,cmap='gray')\n",
    "lab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SVC in module sklearn.svm.classes object:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  SVC(C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to dataset with more than a couple of 10000 samples.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.std())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If probability=True, the parameters learned in Platt scaling to\n",
      " |      produce probability estimates from decision values. If\n",
      " |      probability=False, an empty array. Platt scaling uses the logistic\n",
      " |      function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset. For more\n",
      " |      information on the multiclass case and training procedure see section\n",
      " |      8 of LIBSVM: A Library for Support Vector Machines (in References)\n",
      " |      for more.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  **References:**\n",
      " |  `LIBSVM: A Library for Support Vector Machines\n",
      " |  <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      abc.NewBase\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Distance of the samples X to the separating hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes)\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm=svm.SVC(kernel='linear')\n",
    "svm.C=1e3\n",
    "svm.random_state=0\n",
    "help(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(iris_X_train,iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(iris_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lab.scatter(iris_X_train[:,0],iris_X_train[:,1],c=iris_y_train)\n",
    "lab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lab.scatter(iris_X_train[:,1],iris_X_train[:,2],c=iris_y_train)\n",
    "lab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lab.scatter(iris_X_train[:,2],iris_X_train[:,0],c=iris_y_train)\n",
    "lab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.kernel='rbf'\n",
    "svm.C=1\n",
    "svm.gamma='scale'\n",
    "svm.fit(iris_X_train[:,1:],iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(iris_X_test[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.kernel='rbf'\n",
    "svm.C=1000\n",
    "svm.gamma='scale'\n",
    "svm.fit(iris_X_train[:,[0,2]],iris_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(iris_X_test[:,[0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "dat=iris_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold=KFold(n_splits=5)\n",
    "log=LogisticRegression()\n",
    "log.solver='lbfgs'\n",
    "log.multi_class='multinomial'\n",
    "log.C=1e5\n",
    "log.max_iter=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "for train_indices,test_indices in k_fold.split(dat):\n",
    "    score.append(log.fit(dat[train_indices],iris_y[train_indices]).score(dat[test_indices],iris_y[test_indices]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogisticRegression in module sklearn.linear_model.logistic object:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.8333333333333334, 0.9666666666666667, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple use of cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.83333333, 0.96666667, 0.83333333])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(log,iris_X,iris_y,cv=k_fold,n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different cross validation generator\n",
    "\n",
    "### KFold (n_split, shuffle, random_state)\n",
    "splits it into K fold, trains on K-1 and then test on the left-out\n",
    "### StratifiedKFold(n_splits, shuffle, random_state)\n",
    "Same as KFold but preserves the class distribution within each fold\n",
    "### GroupKFold(n_splits)\n",
    "Ensures that the same group is not in both testing and training sets\n",
    "### ShuffleSplit(n_splits,test_size,train_size,random_state)\n",
    "Generates train/test indices based on random permutations\n",
    "### StratifitedShuffleSplit()\n",
    "Same as shuffle split but preserves the class distribution within each iterations\n",
    "### GroupShuffleSplit\n",
    "ensures that the group is not the testing and training sets\n",
    "### LeaveOneGropuOut()\n",
    "takes a group array to group observations\n",
    "### LeavePGroupOut(n-groups)\n",
    "Leaves n groups out\n",
    "### LeaveOneOut()\n",
    "Leave one observation out\n",
    "### LeavePOut(p)\n",
    "leave p obervations out\n",
    "### PredefinedSplit\n",
    "Generates train/test indices based on predefiend splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-10, 1.29154967e-09, 1.66810054e-08, 2.15443469e-07,\n",
       "       2.78255940e-06, 3.59381366e-05, 4.64158883e-04, 5.99484250e-03,\n",
       "       7.74263683e-02, 1.00000000e+00])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn import datasets, svm\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "svc = svm.SVC(kernel='linear')\n",
    "C_s = np.logspace(-10, 0, 10)\n",
    "C_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[]\n",
    "for var in C_s:\n",
    "    svc.C=var\n",
    "    s=cross_val_score(svc,X,y,cv=kfold,n_jobs=1)\n",
    "    score.append(s)\n",
    "score=num.matrix(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "for var in range(5):\n",
    "    ax.plot(C_s,score[:,var],lw=2)\n",
    "ax.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search \n",
    "Scikit learn provides an object that, given data, computers the score during the fit of an estimator on a parameter grid and chooses the parameter to maximize the cross-validation score. This object takes an estimator during the construction and exposes an estimator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs=num.logspace(-6,-1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GridSearchCV(estimator=svc,param_grid=dict(C=Cs),n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/manu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'C': array([1.00000e-06, 3.59381e-06, 1.29155e-05, 4.64159e-05, 1.66810e-04,\n",
       "       5.99484e-04, 2.15443e-03, 7.74264e-03, 2.78256e-02, 1.00000e-01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(digits_X_train,digits_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776161163961947"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
